- Models are download in ~/.cache/huggingface/hub
- Use huggingface-cli download <model-name>
- Working configuration:
	==((====))==  Unsloth 2025.1.8: Fast Llama patching. Transformers: 4.48.2.
   	\\   /|    GPU: NVIDIA A100-SXM4-40GB. Max memory: 39.394 GB. Platform: Linux.
	O^O/ \_/ \    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0
	\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post2. FA2 = False]
 	"-____-"     Free Apache license: http://github.com/unslothai/unsloth
